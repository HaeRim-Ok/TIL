# kops

kops (Kubernetes Operation): 클라우드 환경에서 쿠버네티스 생성 및 관리를 쉽게 하도록 도와주는 오픈소스 툴

<br>

# 1. 작업환경 구축

### 가상머신 준비

AWS EC2 인스턴스 생성 

- Ubuntu 18.04 AMI 선택
- 스토리지 크기 : 20
- 태그 : Name - k8s-ec2
- 보안그룹 : k8s-security-group, 내 IP만 허용
- 새 키 페어 생성 : k8s-ec2

![image](https://user-images.githubusercontent.com/77096463/112075064-1016b180-8bbb-11eb-9609-f2f5fe41e979.png)

<br>

탄력적 IP 주소 생성하여 k8s-ec2 인스턴스와 연결 > 재연결 시 퍼블릭 ip주소가 계속 바뀌기 때문에

![image](https://user-images.githubusercontent.com/77096463/112075207-65eb5980-8bbb-11eb-9e8d-9ddd9758886a.png)

<br>

### 인스턴스 접속 (xshell)

[cmd] ubuntu 18.04 AMI는 ubuntu로 사용자가 정해져 있음

```
C:\Users\Lenovo>cd C:\Users\Lenovo\Downloads

C:\Users\Lenovo\Downloads>ssh -i k8s-ec2.pem ubuntu@18.xx.xx.xx
The authenticity of host '18.xx.xx.xx (18.xx.xx.xx)' can't be established.
ECDSA key fingerprint is SHA256:CQCpxXqXXEofODPIlXoos5JWZOJaZS+9GsSs7ieQzjg.
Are you sure you want to continue connecting (yes/no)? yes
```

<br>

만일 접속이 안된다면 .ssh 라는 히든 폴더로 이동하여 known_hosts 내용 지운 다음 위의 명령어 재수행

```
C:\Users\Lenovo>cd .ssh
```

<br>

[xshell 연결 탭]

- 이름 : EC2-kops
- 호스트 : 인스턴스 퍼블릭 IPV4 주소
- 포트 번호 : 22

[xshell 사용자 인증 탭]

- 사용자 이름 : ubuntu
- 방법 : Public Key > k8s-ec2 키 페어 가져오기 후 선택

![image](https://user-images.githubusercontent.com/77096463/112076499-df844700-8bbd-11eb-9884-4f056692ee02.png)

<br>

### kops 설치

만일 wget이 없다면 `apt-get install -y wget`

```
$ wget -O kops https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64
$ chmod +x ./kops
$ sudo mv ./kops /usr/local/bin/kops
```

<br>

### kubectl 설치

```
$ wget -O kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
$ chmod +x ./kubectl
$ sudo mv ./kubectl /usr/local/bin/kubectl
```

<br>

### IAM - 그룹 생성, 사용자 생성

그룹 생성

- 이름 : k8s-group
- 정책 : 5가지 선택 (아래 화면 참고)

![image](https://user-images.githubusercontent.com/77096463/112079009-ca5de700-8bc2-11eb-8bac-6e59727406d7.png)

<br>

사용자 추가

- 사용자 이름 : k8s-user
- 액세스 유형 : 프로그래밍 방식 액세스 / AWS Management Console 액세스
- 그룹 k8s-group 선택
- 태그 : name - k8s-users
- 액세스 키  ID, 비밀 액세스 키 반드시 다운받기

![image](https://user-images.githubusercontent.com/77096463/112079465-8c14f780-8bc3-11eb-835c-00ab020468fd.png)

<br>

### AWS CLI 설치 후 설정

`aws configure` 명령어 입력 후 다운받은 사용자 액세스 키 ID, 비밀 액세스 키 값 입력 

```
$ sudo apt update
$ sudo apt-get install -y python3-pip
$ sudo apt install awscli

$ aws configure
AWS Access Key ID [None]: AKIXXXXXXXXXXXXXXXXXX
AWS Secret Access Key [None]: /jyrXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Default region name [None]: us-east-1
Default output format [None]: 

$ aws ec2 describe-instances
$ aws iam list-users
{
    "Users": [
        {
            "Path": "/",
            "UserName": "k8s-user",
            "UserId": "AIDATXJSWD4OSGUD5BY7O",
            "Arn": "arn:aws:iam::256193732381:user/k8s-user",
            "CreateDate": "2021-03-23T01:34:43Z"
        }
    ]
}
```

<br>



# 2. 클러스터 생성

### S3 버킷 생성

```
$ aws s3api create-bucket --bucket haerim --region us-east-1
{
    "Location": "/haerim"
}

$ aws s3api put-bucket-versioning --bucket haerim --versioning-configuration Status=Enabled
```

<br>

### 환경 변수 설정

```
$ export AWS_ACCESS_KEY_ID=$<access_ID>
$ export AWS_SECRET_ACCESS=$<secret_access_key>
$ export NAME=haerimcluster.k8s.local
$ export KOPS_STATE_STORE=s3://haerim
```

<br>

### SSH Key Pair 생성

rsa 알고리즘을 사용하는 키페어 생성

```
$ ssh-keygen -t rsa

$ ls -al /home/ubuntu/.ssh/
total 20
drwx------ 2 ubuntu ubuntu 4096 Mar 23 02:20 .
drwxr-xr-x 7 ubuntu ubuntu 4096 Mar 23 01:42 ..
-rw------- 1 ubuntu ubuntu  389 Mar 23 00:33 authorized_keys
-rw------- 1 ubuntu ubuntu 1679 Mar 23 02:20 id_rsa
-rw-r--r-- 1 ubuntu ubuntu  405 Mar 23 02:20 id_rsa.pub
```

<br>

### 사용 가능한 AZ 확인

```
$ aws ec2 describe-availability-zones --region us-east-1
{
    "AvailabilityZones": [
        {
            "State": "available",
            "OptInStatus": "opt-in-not-required",
            "Messages": [],
            "RegionName": "us-east-1",
            "ZoneName": "us-east-1a",
            "ZoneId": "use1-az1",
            "GroupName": "us-east-1",
            "NetworkBorderGroup": "us-east-1",
            "ZoneType": "availability-zone"
        },
        {
...
```

<br>

### 클러스터 생성을 위한 AZ 지정

ig : instance group

```
$ kops create cluster --zones us-east-1a ${NAME}
$ kops edit cluster ${NAME}
$ kops get ig --name ${NAME}
NAME			ROLE	MACHINETYPE	MIN	MAX	ZONES
master-us-east-1a	Master	t3.medium	1	1	us-east-1a
nodes-us-east-1a	Node	t3.medium	1	1	us-east-1a
```

<br>

### 마스터 노드 확인, 노드 수 조절

Master : 1개, Node는 3개 정도로 조절

- Master 갯수에 따라 EC2 인스턴스의 갯수도 증가 및 감소하니 조심하기
- machineType : t2.micro 설정

```
$ kops edit ig master-us-east-1a --name ${NAME}
$ kops edit ig nodes-us-east-1a --name ${NAME}
```

![image](https://user-images.githubusercontent.com/77096463/112084617-748e3c80-8bcc-11eb-8f0e-b47904af2954.png)

<br>

### 클러스터 생성

```
$ kops update cluster ${NAME} --yes
```

명령어 수행 후 콘솔창에서 인스턴스 상태를 확인하면 설정한 마스터 노드 1개와 워커노드 3개가 생성되었음을 확인

![image](https://user-images.githubusercontent.com/77096463/112085422-d4d1ae00-8bcd-11eb-9cc0-a793c9aa9ccc.png)

<br>

:rotating_light:**트러블슈팅 - Validation failed: unexpected error during validation: error listing nodes: Unauthorized**

> `kops validate cluster` 명령어 입력 시 위와 같이 unauthroized 오류가 나는데 이는 기존의 클러스터를 지우고 새로운 클러스터 생성 시 kubeconfig에 예전 계정이 남아있어 kOps/kubectl가 기존 계정을 다시 사용하기에 나는 오류이다. 
>
> `kops export kubecfg ${NAME} --admin` 명령어 입력 후  `kops validate cluster` 실행하면 오류 해결~! 

도메인 등록

```
$ kops export kubecfg ${NAME} --admin
```



### 클러스터 테스트

클러스터 생성하고 마스터, 워커 노드 설정하는 과정에서 시간이 걸릴 수 있음

```
$ kops validate cluster
Using cluster from kubectl context: haerimcluster.k8s.local

Validating cluster haerimcluster.k8s.local

INSTANCE GROUPS
NAME			ROLE	MACHINETYPE	MIN	MAX	SUBNETS
master-us-east-1a	Master	t2.micro	1	1	us-east-1a
nodes-us-east-1a	Node	t2.micro	3	3	us-east-1a

NODE STATUS
NAME				ROLE	READY
ip-172-20-32-19.ec2.internal	node	True
ip-172-20-32-54.ec2.internal	node	True
ip-172-20-34-254.ec2.internal	master	True
ip-172-20-62-225.ec2.internal	node	True

Your cluster haerimcluster.k8s.local is ready
```

<br>

중간중간 자꾸 아래와 같은 validation error가 나오는데 10분 정도 기다리니 해결됐다

```
VALIDATION ERRORS
KIND	NAME									MESSAGE
Pod	kube-system/kube-controller-manager-ip-172-20-34-254.ec2.internal	system-cluster-critical pod "kube-controller-manager-ip-172-20-34-254.ec2.internal" is not ready (kube-controller-manager)
Pod	kube-system/kube-scheduler-ip-172-20-34-254.ec2.internal		system-cluster-critical pod "kube-scheduler-ip-172-20-34-254.ec2.internal" is not ready (kube-scheduler)

Validation Failed

Validation failed: cluster not yet healthy
```

<br>

### 클러스터 삭제

```
$ kops delete cluster --name ${NAME} --yes
```

